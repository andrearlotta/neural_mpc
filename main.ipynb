{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train surrogate model\n",
    "\n",
    "With the previous data, train a surrogate model (gaussian process or NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "We use data from a file or a function generation to train a perception surrogate $g(\\Delta x)$.\n",
    "In this case $\\Delta x$ is defined as the relative position (distance) between a tree and the drone: $\\Delta x = \\| x - t_i \\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gausspdf(x, mu, sigma):\n",
    "  return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "\n",
    "# Plot for testing\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = gausspdf(x, 4, 1.3) + 0.5\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import norm  # For Gaussian PDF\n",
    "def fake_confidence(drone_pos, tree_pos, include_yaw=True, fov=20):\n",
    "    \"\"\"\n",
    "    Simulates the confidence output of the NN.\n",
    "    \"\"\"\n",
    "    direction = tree_pos - drone_pos[:2]\n",
    "    distance = np.linalg.norm(direction)\n",
    "    result = np.full_like(distance, 0.5)\n",
    "    \n",
    "    if include_yaw:\n",
    "        theta = drone_pos[2]\n",
    "        drone_forward = np.array([np.cos(theta), np.sin(theta)])\n",
    "        n_direction = direction / distance\n",
    "        ang_fov_tree = n_direction.T @ drone_forward  # Dot product (cos(angolo))\n",
    "\n",
    "        fov_threshold = np.cos(np.deg2rad(fov))\n",
    "    \n",
    "    if distance < 0.001 or distance > 10:\n",
    "        result = 0.5\n",
    "    elif include_yaw and ang_fov_tree < fov_threshold:  # Tree oustide the fov\n",
    "        result = 0.5\n",
    "    else:\n",
    "        result = norm.pdf(distance, loc=2.5, scale=1) + 0.5\n",
    "        \n",
    "    return result\n",
    "\n",
    "def generate_fake_dataset(\n",
    "    samples_xy, \n",
    "    samples_yaw, \n",
    "    x_dimension, \n",
    "    use_fov=True,\n",
    "    x_low=-8,          # Lower bound for drone X position\n",
    "    x_high=8,          # Upper bound for drone X position\n",
    "    y_low=-8,          # Lower bound for drone Y position\n",
    "    y_high=8,          # Upper bound for drone Y position\n",
    "    tree_low=-8,       # Lower bound for tree position\n",
    "    tree_high=8        # Upper bound for tree position\n",
    "):\n",
    "    synthetic_X = []\n",
    "    synthetic_Y = []\n",
    "    \n",
    "    # Define ranges for drone positions with parameterized bounds\n",
    "    x_range = np.linspace(x_low, x_high, samples_xy)\n",
    "    y_range = np.linspace(y_low, y_high, samples_xy)\n",
    "    yaw_range = np.linspace(-np.pi, np.pi, samples_yaw)\n",
    "\n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            if use_fov:\n",
    "                for yaw in yaw_range:\n",
    "                    tree_pos = np.random.uniform(low=tree_low, high=tree_high, size=(1, 2))\n",
    "                    drone_pos = np.array([x, y, yaw])\n",
    "                    value = fake_confidence(drone_pos, tree_pos.flatten(), use_fov)\n",
    "                    synthetic_X.append(\n",
    "                        np.concatenate((drone_pos[:x_dimension], tree_pos.flatten()))\n",
    "                    )\n",
    "                    synthetic_Y.append(value)\n",
    "            else:\n",
    "                tree_pos = np.random.uniform(low=tree_low, high=tree_high, size=(1, 2))\n",
    "                drone_pos = np.array([x, y, -np.arctan2(y, x)])\n",
    "                value = fake_confidence(drone_pos, tree_pos.flatten(), use_fov)\n",
    "                synthetic_X.append(\n",
    "                    np.concatenate((drone_pos[:x_dimension], tree_pos.flatten()))\n",
    "                )\n",
    "                synthetic_Y.append(value)\n",
    "    \n",
    "    return torch.Tensor(np.array(synthetic_X)), torch.Tensor(np.array(synthetic_Y))\n",
    "use_fov = True\n",
    "\n",
    "X, Y = generate_fake_dataset(\n",
    "    samples_xy=40, \n",
    "    samples_yaw=10, \n",
    "    x_dimension=3,\n",
    "    use_fov=True,\n",
    "    x_low=-10,        # Drone X ranges from -10 to 10\n",
    "    x_high=10,\n",
    "    y_low=-10,         # Drone Y ranges from -5 to 5\n",
    "    y_high=10,\n",
    "    tree_low=0,     # Tree ranges from -15 to 15\n",
    "    tree_high=0\n",
    ")\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Targets shape:\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "hidden_layers = 3\n",
    "\n",
    "# Simple NN\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.input_layer = torch.nn.Linear(input_dim if not input_dim== 3 else input_dim+1, hidden_size)\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(3):\n",
    "            hidden_layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "        self.hidden_layer = torch.nn.ModuleList(hidden_layers)\n",
    "        self.out_layer = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.shape[-1] == 3:  # Check if the input has 3 dimensions\n",
    "            # Replace the angle with its sin and cos values\n",
    "            sin_cos = torch.cat([torch.sin(x[..., -1:]), torch.cos(x[..., -1:])], dim=-1)\n",
    "            x = torch.cat([x[..., :-1], sin_cos], dim=-1)\n",
    "            x = self.input_layer(x)\n",
    "        for layer in self.hidden_layer:\n",
    "            x = torch.tanh(layer(x))\n",
    "        x = self.out_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "\n",
    "nn_input_dim = 3\n",
    "train = False\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "epochs = 4\n",
    "validation_split = 0.2\n",
    "\n",
    "# Directory to save models\n",
    "model_dir = f\"saved_models_{nn_input_dim}d\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Prepare dataset\n",
    "X = X[:,:3]\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "if   train:\n",
    "    # Train-validation split\n",
    "    num_train_samples = int((1 - validation_split) * len(dataset))\n",
    "    num_val_samples = len(dataset) - num_train_samples\n",
    "    train_dataset, val_dataset = random_split(dataset, [num_train_samples, num_val_samples])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model =  MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "\n",
    "    # Set up TensorBoard logging\n",
    "    log_dir = f\"runs/fcn_{datetime.datetime.now().strftime('%Y)-%m-%d_%H-%M-%S')}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "    # Training loop with validation\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # Train step\n",
    "        train_loss = 0\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(val_loader):\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        \n",
    "        # Save the model if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            model_path = os.path.join(model_dir, f\"best_model_epoch_{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_latest_best_model(model_dir):\n",
    "    # Find the latest best model file\n",
    "    latest_model = max(\n",
    "        (f for f in os.listdir(model_dir) if re.match(r\"best_model_epoch_(\\d+)\\.pth\", f)),\n",
    "        key=lambda x: int(re.match(r\"best_model_epoch_(\\d+)\\.pth\", x).group(1))\n",
    "    )\n",
    "    return os.path.join(model_dir, latest_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,  # 1 row, 2 columns\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],  # Both subplots are 3D scatter plots\n",
    "    subplot_titles=(\"Ground Truth\", \"Predicted\")  # Titles for each subplot\n",
    ")\n",
    "\n",
    "X, Y = generate_fake_dataset(\n",
    "    samples_xy=40, \n",
    "    samples_yaw=10, \n",
    "    x_dimension=3,\n",
    "    use_fov=True,\n",
    "    x_low=-8,        # Drone X ranges from -10 to 10\n",
    "    x_high=8,\n",
    "    y_low=-8,         # Drone Y ranges from -5 to 5\n",
    "    y_high=8,\n",
    "    tree_low=0,     # Tree ranges from -15 to 15\n",
    "    tree_high=0\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(z=Y.flatten(), x=X[:,0], y=X[:,1], name='Ground Truth',marker=dict(\n",
    "        color=Y.flatten(),  # Color based on z values\n",
    "        colorscale='Viridis',     # Use Viridis color map\n",
    "        colorbar=dict(title='Z Value'),  # Add color bar\n",
    "        size=5,                   # Marker size\n",
    "        opacity=0.8               # Marker opacity\n",
    "    ),), row=1, col=1)  # Add to the first subplot\n",
    "\n",
    "\n",
    "model = MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "model.load_state_dict(torch.load(get_latest_best_model(model_dir)))\n",
    "model.eval()\n",
    "\n",
    "X = X[:,:3]\n",
    "# Model prediction\n",
    "with torch.no_grad():\n",
    "    y_test = model(X).detach().numpy()\n",
    "\n",
    "# Add predicted trace to the second subplot\n",
    "fig.add_trace(go.Scatter3d(z=y_test.flatten(),x=X[:, 0],y=X[:, 1],name='Predicted',mode='markers',marker=dict(\n",
    "        color=y_test.flatten(),  # Color based on z values\n",
    "        colorscale='Viridis',     # Use Viridis color map\n",
    "        colorbar=dict(title='Z Value'),  # Add color bar\n",
    "        size=5,                   # Marker size\n",
    "        opacity=0.8               # Marker opacity\n",
    "    )\n",
    "), row=1, col=2)  # Add to the second subplot\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Ground Truth vs Predicted\",  # Main title\n",
    "    scene=dict(  # Update the first subplot's scene\n",
    "        xaxis_title=\"x1\",\n",
    "        yaxis_title=\"x2\",\n",
    "        zaxis_title=\"Output\"\n",
    "    ),\n",
    "    scene2=dict(  # Update the second subplot's scene\n",
    "        xaxis_title=\"x1\",\n",
    "        yaxis_title=\"x2\",\n",
    "        zaxis_title=\"Output\"\n",
    "    ),\n",
    "    showlegend=False  # Hide legend for clarity\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the working environment\n",
    "\n",
    "The problem definition is as follows:\n",
    "\n",
    "$x$ state of the robot defined by the position of the drone and its velocity [x, y ,z, vx, vy, vz]\n",
    "\n",
    "$f(x, u)$ state transition function for the drone\n",
    "\n",
    "$u$ acceleration commands to the drone [ax, ay, az]\n",
    "\n",
    "$t \\in T$ tree positions for the $T$ trees [[tx_1, ty_2], ... , [tx_T, ty_T]]\n",
    "\n",
    "$\\lambda$ belief for the trees maturity confidence [\\lambda_1, ..., \\lambda_T] (values from 0 to 1). For practicity, it can be seen as part of $x$\n",
    "\n",
    "$z$ observation vector for the tree maturity confidence [z_1, ..., z_T] (values from 0 to 1)\n",
    "\n",
    "$g(\\Delta x)$ observation surrogate. It is applied to every tree.\n",
    "\n",
    "$b(\\lambda, z)$ bayesian update to the previous belief.\n",
    "\n",
    "$H(\\lambda)$ entropy function for the belief defined (for the case of binary distribution) as: $-\\lambda \\log{\\lambda} - (1-\\lambda) \\log(1-\\lambda)$.\n",
    "\n",
    "$J(\\lambda)$ the cost function of the MPC defined as: $\\sum_{1, ..., n} \\delta_1 H(\\lambda_i) * \\delta_2 \\Delta x_i^2 + \\delta_3 \\|u\\|$. They correspond to trying to reduce the entropy for each of the trees using $\\Delta x_i^2$ to guide the planner when there is no observation, and reduce the control inputs.\n",
    "\n",
    "The steps of the system are as follows:\n",
    "1. Load learned $g()$ which works for one tree.\n",
    "2. Initialize $x$ in a $x_0$ position, $\\lambda$ with $0.5$ values for each tree, and $t$ as known.\n",
    "3. Run the NMPC from $x$ for $N$ iterations. In each step:\n",
    "  - Compute $\\Delta x$ for each tree with the new drone $x$.\n",
    "  - Get estimation from NN for each tree: $z = g(\\Delta x)$.\n",
    "  - Fuse the estimation in $\\lambda$ for each tree: $\\lambda_{k} = b(\\lambda_{k-1}, z)$\n",
    "4. Apply the solution from the MPC.\n",
    "5. Get a real observation.\n",
    "6. Integrate the real observation into $\\lambda$.\n",
    "7. Go back to step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import casadi as ca\n",
    "# Define the entropy function\n",
    "def entropy(lambda_val):\n",
    "    return (-lambda_val * ca.log10(lambda_val) - (1 - lambda_val) * ca.log10(1 - lambda_val))/ca.log10(2)\n",
    "\n",
    "# Generate lambda values (avoid 0 and 1 to prevent log(0) errors)\n",
    "x = np.linspace(0.01, 0.99, 100)\n",
    "\n",
    "# Compute entropy values\n",
    "entropy_vals = entropy(x)\n",
    "\n",
    "# Plot the entropy function\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, entropy_vals, label=\"Entropy\", color=\"blue\")\n",
    "plt.title(\"Entropy Function\")\n",
    "plt.xlabel(\"Lambda (λ)\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import casadi as ca\n",
    "import l4casadi as l4c\n",
    "import time\n",
    "\n",
    "# Constants\n",
    "T = 1.0\n",
    "N = 10\n",
    "dt = T / N\n",
    "nx = 3  # Represents position (x, y, theta) and velocity (vx, vy, omega)\n",
    "\n",
    "def generate_tree_positions(grid_size, spacing):\n",
    "    \"\"\"Generate tree positions in a grid.\"\"\"\n",
    "    x_positions = np.arange(0, grid_size[0]*spacing, spacing)\n",
    "    y_positions = np.arange(0, grid_size[1]*spacing, spacing)\n",
    "    xv, yv = np.meshgrid(x_positions, y_positions)\n",
    "    tree_positions = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "    return tree_positions + 0.1\n",
    "\n",
    "def get_domain(tree_positions):\n",
    "    \"\"\"Return the domain (bounding box) of the tree positions.\"\"\"\n",
    "    x_min = np.min(tree_positions[:, 0])\n",
    "    x_max = np.max(tree_positions[:, 0])\n",
    "    y_min = np.min(tree_positions[:, 1])\n",
    "    y_max = np.max(tree_positions[:, 1])\n",
    "    return [x_min,y_min], [x_max, y_max]\n",
    "\n",
    "def kin_model(T=1.0, N=20):\n",
    "    # Correct kinematic model with state [x, y, theta, vx, vy, omega]\n",
    "    x = ca.MX.sym('x', nx*2)\n",
    "    u = ca.MX.sym('u', nx)  # Control: [acc_x, acc_y, angular_acc]\n",
    "    xf = x + dt * ca.vertcat(x[nx:], u)\n",
    "    return ca.Function('F', [x, u], [xf])\n",
    "\n",
    "# Bayesian update function\n",
    "def bayes(lambda_prev, z):\n",
    "    prod = lambda_prev * z\n",
    "    return prod / (prod + (1 - lambda_prev) * (1 - z))\n",
    "\n",
    "\n",
    "# MPC optimization using CasADi\n",
    "def mpc_opt(g_nn, trees, lb, ub, x0, lambda_vals, steps=10):\n",
    "    opti = ca.Opti()\n",
    "    F_ = kin_model(T=1.0, N=steps)\n",
    "\n",
    "    P0 = opti.parameter(nx*2 + len(trees))\n",
    "    X = opti.variable(nx*2, steps + 1)\n",
    "    U = opti.variable(nx, steps)\n",
    "\n",
    "    opti.subject_to(X[:, 0] == P0[:nx*2])\n",
    "    lambda_k = P0[nx*2:]\n",
    "\n",
    "    for i in range(steps):\n",
    "        # State constraints\n",
    "        opti.subject_to(opti.bounded(lb[0]-3, X[0, i+1], ub[0]+3))\n",
    "        opti.subject_to(opti.bounded(lb[1]-3, X[1, i+1], ub[1]+3))\n",
    "        opti.subject_to(opti.bounded(-10, X[3, i+1], 10))  # Velocity constraints\n",
    "        opti.subject_to(opti.bounded(-10, X[4, i+1], 10))  # Velocity constraints\n",
    "        opti.subject_to(opti.bounded(-3.14, X[5, i+1], 3.14))  # Angular velocity\n",
    "        opti.subject_to(opti.bounded(-10, U[:2, i], 10))  # Acceleration constraints\n",
    "        opti.subject_to(opti.bounded(-3.14, U[2, i], 3.14))  # Angular acceleration\n",
    "        opti.subject_to(X[:, i+1] == F_(X[:, i], U[:, i]))\n",
    "\n",
    "        # Calculate relative positions and distances\n",
    "        relative_pos = ca.repmat(X[:2, i+1].T, trees.shape[0], 1) - trees\n",
    "        squared_dist = ca.sum2(relative_pos**2)  # Correct distance calculation\n",
    "        within_range = squared_dist <= 100\n",
    "\n",
    "        # Neural network input and prediction\n",
    "        heading = ca.repmat(X[2, i+1], trees.shape[0], 1)\n",
    "        nn_input = ca.horzcat(relative_pos, heading)\n",
    "        g_out = g_nn(nn_input)\n",
    "        already_seen = (lambda_k[:,-1] < 0.9)\n",
    "        z_k = ca.fmax(g_out, 0.5) #* already_seen + 0.5 * (1- already_seen)\n",
    "\n",
    "        # Bayesian update\n",
    "        bayes_update = bayes(lambda_k[:,-1], z_k)\n",
    "        lambda_k = ca.horzcat(lambda_k, bayes_update)\n",
    "\n",
    "    # Objective function: Minimize the entropy\n",
    "    obj = 0\n",
    "    for i in range(steps):\n",
    "        # Compute here the relative position of the drone wrt to the tree\n",
    "        obj += ca.sum1(entropy(lambda_k[:, i+1]) - entropy(lambda_k[:, i]))\n",
    "\n",
    "    obj += 1e-5 * ca.sumsqr(U[:2,:]) + 1e-8 * ca.sumsqr(U[2,:])\n",
    "    opti.minimize(obj)\n",
    "    options = {\"ipopt\": {\"tol\":1e-5, \"warm_start_init_point\" : 'no', \"hessian_approximation\": \"limited-memory\", \"print_level\":0, \"sb\": \"no\", \"mu_strategy\": \"monotone\", \"max_iter\":500}} #reduced print level\n",
    "    opti.solver('ipopt', options)\n",
    "\n",
    "    # Initial step    \n",
    "    opti.set_value(P0, ca.vertcat(x0, lambda_vals))\n",
    "\n",
    "    sol = opti.solve()\n",
    "\n",
    "    inputs = [P0, opti.x,opti.lam_g]\n",
    "    outputs = [U[:,0], X, opti.x, opti.lam_g]\n",
    "    mpc_step = opti.to_function('mpc_step',inputs,outputs)\n",
    "\n",
    "    return mpc_step, ca.DM(sol.value(U[:,0])), ca.DM(sol.value(X)), ca.DM(sol.value(opti.x)), ca.DM(sol.value(opti.lam_g))\n",
    "\n",
    "# Main loop\n",
    "def main():\n",
    "\n",
    "    # Step 2: Initialize x in a x_0 position, lambda$ with 0.5 values for each tree, and t as known.\n",
    "    trees = generate_tree_positions ([5,5],4)\n",
    "    lb, ub = get_domain(trees)\n",
    "    lambda_k = ca.DM.ones(len(trees)) * 0.5\n",
    "    mpc_horizon = N\n",
    "\n",
    "\n",
    "    # Step 1: Load learned g(.) which works for one tree.\n",
    "    model = MultiLayerPerceptron(input_dim=nn_input_dim) \n",
    "    model.load_state_dict(torch.load(get_latest_best_model(model_dir)))\n",
    "    model.eval()\n",
    "    g_nn = l4c.L4CasADi(model, generate_jac_jac=True, batched=True, device='cuda')\n",
    "\n",
    "    # Initialize robot state\n",
    "    x0 = ca.vertcat( ca.DM.ones(nx), ca.DM.zeros(nx))\n",
    "\n",
    "    # Log\n",
    "    all_trajectories = []\n",
    "    lambda_history = []\n",
    "    entropy_history = []\n",
    "    durations = []\n",
    "\n",
    "    # Step 2.5: Initialize mpc\n",
    "    mpc_step, u, x_, x, lam = mpc_opt(g_nn, trees,lb, ub, x0, lambda_k,mpc_horizon)\n",
    "\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < 700:\n",
    "        iteration += 1\n",
    "\n",
    "        # Logging phase\n",
    "        lambda_history.append(lambda_k.full().flatten().tolist())\n",
    "        entropy_history.append(ca.sum1(entropy(lambda_k)).full().flatten().tolist()[0])\n",
    "        all_trajectories.append( x_[:nx,:].full())\n",
    "\n",
    "        # Step 4: Apply command to the drone (update its pose)\n",
    "        x0 =  x_[:,1].full().flatten()\n",
    "\n",
    "        # Step 5: Get a real observation (simulated)\n",
    "\n",
    "        nn_inference = []\n",
    "        z_k = ca.vertcat(*[fake_confidence(x0, tree, fov=25) for tree in trees])\n",
    "        \n",
    "        # Step 6: Integrate observation into lambda\n",
    "        lambda_k = bayes(lambda_k,z_k)    \n",
    "\n",
    "        # Step 3: Run MPC\n",
    "        start_time = time.time()\n",
    "        u, x_, x, lam = mpc_step(ca.vertcat(x0, lambda_k), x, lam)\n",
    "        durations.append( time.time() - start_time)\n",
    "        entropy_k = ca.sum1(entropy(lambda_k)).full().flatten()[0]\n",
    "\n",
    "        print(f\"Iteration {iteration}: x={x0}, Weights sum = {entropy_k}, {lambda_k}\") #log the position and weight sum\n",
    "        if entropy_k < 0.5:\n",
    "            break\n",
    "    \n",
    "    return all_trajectories, entropy_history, lambda_history, durations, g_nn, trees, lb, ub\n",
    "\n",
    "all_trajectories, entropy_history, lambda_history, durations, g_nn, trees, lb, ub = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "def plot_animated_trajectory_and_entropy_2d(all_trajectories, entropy_history, lambda_history, trees, lb, ub, computation_durations):\n",
    "    print(np.array(all_trajectories).shape)\n",
    "    \n",
    "    # Extract trajectory data\n",
    "    x_trajectory = np.array([traj[0] for traj in all_trajectories])\n",
    "    y_trajectory = np.array([traj[1] for traj in all_trajectories])\n",
    "    theta_trajectory = np.array([traj[2] for traj in all_trajectories])  # Drone orientation (yaw)\n",
    "    all_trajectories = np.array(all_trajectories)\n",
    "    lambda_history = np.array(lambda_history)\n",
    "    \n",
    "    # Compute entropy reduction for each step\n",
    "    entropy_mpc_pred = []\n",
    "    for k in range(all_trajectories.shape[0]):\n",
    "        lambda_k = lambda_history[k]\n",
    "        entropy_mpc_pred_k = [entropy_history[k]]  # Start with the initial entropy value\n",
    "        for i in range(all_trajectories.shape[2]-1):\n",
    "            relative_position_robot_trees = np.tile(all_trajectories[k,:2,i+1], (trees.shape[0], 1)) - trees\n",
    "            distance_robot_trees = np.sqrt(np.sum(relative_position_robot_trees**2, axis=1))\n",
    "            theta =  np.tile(all_trajectories[k,2,i+1], (trees.shape[0], 1))  # Drone yaw\n",
    "            input_nn = ca.horzcat(relative_position_robot_trees, theta) # horzcat(np.tile(all_trajectories[k,:3,i+1], (trees.shape[0], 1)), trees)\n",
    "            z_k = (distance_robot_trees > 10) * 0.5 + (distance_robot_trees <= 10) * ca.fmax(g_nn(input_nn), 0.5)\n",
    "            lambda_k = bayes(lambda_k, z_k)\n",
    "            reduction = ca.sum1(entropy(lambda_k)).full().flatten()[0]\n",
    "            entropy_mpc_pred_k.append(reduction)\n",
    "        entropy_mpc_pred.append(entropy_mpc_pred_k)\n",
    "    \n",
    "    entropy_mpc_pred = np.array(entropy_mpc_pred)\n",
    "\n",
    "    # Compute the sum of entropies for all trees at each frame\n",
    "    sum_entropy_history = entropy_history\n",
    "\n",
    "    # Compute cumulative computation durations\n",
    "    cumulative_durations = np.cumsum(computation_durations)\n",
    "    # Create a subplot with 2 rows and 2 columns\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        column_widths=[0.7, 0.3],\n",
    "        row_heights=[0.6, 0.4],\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],  # First row: 2D map and entropy plot\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]   # Second row: empty and computation durations plot\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Add the initial trajectory (2D scatter plot) to the first subplot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_trajectory[0],\n",
    "            y=y_trajectory[0],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"MPC Future Trajectory\",\n",
    "            line=dict(color=\"red\", width=4),\n",
    "            marker=dict(size=5, color=\"blue\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Drone Trajectory\",\n",
    "            line=dict(color=\"orange\", width=4),\n",
    "            marker=dict(size=5, color=\"orange\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add trees as circles with color based on lambda to the first subplot\n",
    "    for i in range(trees.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[trees[i, 0]],\n",
    "                y=[trees[i, 1]],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=\"#FF0000\",  # Initial color (red)\n",
    "                    colorscale=[[0, \"#FF0000\"], [1, \"#00FF00\"]],  # Red to green\n",
    "                    cmin=0,\n",
    "                    cmax=1,\n",
    "                    showscale=False\n",
    "                ),\n",
    "                name=f\"Tree {i}\"\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # Add the sum of entropies plot to the second subplot (top-right)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Sum of Entropies (Past)\",\n",
    "            line=dict(color=\"blue\", width=2),\n",
    "            marker=dict(size=5, color=\"blue\")\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Sum of Entropies (Future)\",\n",
    "            line=dict(color=\"purple\", width=2, dash=\"dot\"),\n",
    "            marker=dict(size=5, color=\"purple\")\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Add the computation durations plot to the fourth subplot (bottom-right)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Computation Durations\",\n",
    "            line=dict(color=\"green\", width=2),\n",
    "            marker=dict(size=5, color=\"green\")\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "    # Create frames for animation\n",
    "    frames = []\n",
    "    for k in range(len(entropy_mpc_pred)):\n",
    "        # Update tree colors based on lambda values\n",
    "        tree_data = []\n",
    "        for i in range(trees.shape[0]):\n",
    "            tree_data.append(\n",
    "                go.Scatter(\n",
    "                    x=[trees[i, 0]],\n",
    "                    y=[trees[i, 1]],\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=10,\n",
    "                        color=[2*(lambda_history[k][i] - 0.5)],  # Color based on lambda value\n",
    "                        colorscale=[[0, \"#FF0000\"], [1, \"#00FF00\"]],  # Red to green\n",
    "                        cmin=0,\n",
    "                        cmax=1,\n",
    "                        showscale=False\n",
    "                    ),\n",
    "                    name=f\"Tree {i}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Update the sum of entropies plot\n",
    "        sum_entropy_past = sum_entropy_history[:k+1]\n",
    "        sum_entropy_future = entropy_mpc_pred[k]\n",
    "\n",
    "        # Update the computation durations plot\n",
    "        computation_durations_past = computation_durations[:k+1]\n",
    "\n",
    "        # Add drone orientation as an arrow\n",
    "        x_start = x_trajectory[k]  # Drone x position\n",
    "        y_start = y_trajectory[k]  # Drone y position\n",
    "        theta = theta_trajectory[k]  # Drone yaw angle\n",
    "        x_end = x_start + 0.5 * np.cos(theta)  # Arrow end x\n",
    "        y_end = y_start + 0.5 * np.sin(theta)  # Arrow end y\n",
    "\n",
    "        list_of_actual_orientations = []\n",
    "        for x0,y0,x1,y1 in zip(x_start, y_start, x_end, y_end):\n",
    "            arrow = go.layout.Annotation(\n",
    "                dict(\n",
    "                    x=x1,  # Arrow end x\n",
    "                    y=y1,  # Arrow end y\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    text=\"\",\n",
    "                    showarrow=True,\n",
    "                    axref=\"x\", ayref=\"y\",\n",
    "                    ax=x0,  # Arrow start x\n",
    "                    ay=y0,  # Arrow start y\n",
    "                    arrowhead=3,  # Arrowhead size\n",
    "                    arrowwidth=1.5,  # Arrow width\n",
    "                    arrowcolor=\"red\",  # Arrow color\n",
    "                )\n",
    "            )\n",
    "            list_of_actual_orientations.append(arrow)\n",
    "\n",
    "\n",
    "        # Add drone orientation as an arrow\n",
    "        x_start = x_trajectory[:k+1,0]  # Drone x position\n",
    "        y_start = y_trajectory[:k+1,0]  # Drone y position\n",
    "        theta = theta_trajectory[:k+1,0]  # Drone yaw angle\n",
    "        x_end = x_start + 0.5 * np.cos(theta)  # Arrow end x\n",
    "        y_end = y_start + 0.5 * np.sin(theta)  # Arrow end y\n",
    "\n",
    "        for x0,y0,x1,y1 in zip(x_start, y_start, x_end, y_end):\n",
    "            arrow = go.layout.Annotation(\n",
    "                dict(\n",
    "                    x=x1,  # Arrow end x\n",
    "                    y=y1,  # Arrow end y\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    text=\"\",\n",
    "                    showarrow=True,\n",
    "                    axref=\"x\", ayref=\"y\",\n",
    "                    ax=x0,  # Arrow start x\n",
    "                    ay=y0,  # Arrow start y\n",
    "                    arrowhead=3,  # Arrowhead size\n",
    "                    arrowwidth=1.5,  # Arrow width\n",
    "                    arrowcolor=\"orange\",  # Arrow color\n",
    "                )\n",
    "            )\n",
    "            list_of_actual_orientations.append(arrow)\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                go.Scatter(\n",
    "                    x=x_trajectory[k],\n",
    "                    y=y_trajectory[k],\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"red\", width=4),\n",
    "                    marker=dict(size=5, color=\"blue\")\n",
    "                ),\n",
    "                go.Scatter(\n",
    "                    x=x_trajectory[:k+1,0],\n",
    "                    y=y_trajectory[:k+1,0],\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"orange\", width=4),\n",
    "                    marker=dict(size=5, color=\"orange\")\n",
    "                ),\n",
    "                *tree_data,  # Add tree data for this frame\n",
    "                go.Scatter(\n",
    "                    x=np.arange(len(sum_entropy_past)),\n",
    "                    y=sum_entropy_past,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"blue\", width=2),\n",
    "                    marker=dict(size=5, color=\"blue\")\n",
    "                ),\n",
    "                go.Scatter(\n",
    "                    x=np.arange(k, k+len(sum_entropy_future)),\n",
    "                    y=sum_entropy_future,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"purple\", width=2, dash=\"dot\"),\n",
    "                    marker=dict(size=5, color=\"purple\")\n",
    "                ),\n",
    "                go.Scatter(\n",
    "                    x=np.arange(len(computation_durations_past)),\n",
    "                    y=computation_durations_past,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"green\", width=2),\n",
    "                    marker=dict(size=5, color=\"green\")\n",
    "                )\n",
    "            ],\n",
    "            name=f\"Frame {k}\",\n",
    "            layout=dict(annotations=list_of_actual_orientations)  # Add the annotation and arrow to the frame\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Add frames to the figure\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Update layout for the subplots\n",
    "    fig.update_layout(\n",
    "        title=\"Drone Trajectory, Sum of Entropies, and Computation Durations\",\n",
    "        xaxis=dict(title=\"X Position\", range=[lb[0] - 3 , ub[0] + 3]), \n",
    "        yaxis=dict(title=\"Y Position\", range=[lb[1] - 3 , ub[1] + 3]),\n",
    "        xaxis2=dict(title=\"Time Step\"),\n",
    "        yaxis2=dict(title=\"Sum of Entropies\"),\n",
    "        xaxis3=dict(title=\"Time Step\"),\n",
    "        yaxis3=dict(title=\"Computation Duration (s)\"),\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        label=\"Play\",\n",
    "                        method=\"animate\",\n",
    "                        args=[None, {\"frame\": {\"duration\": 200, \"redraw\": True}, \"fromcurrent\": True}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Pause\",\n",
    "                        method=\"animate\",\n",
    "                        args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]\n",
    "                    )\n",
    "                ],\n",
    "                showactive=True,\n",
    "                x=0.1,\n",
    "                y=0\n",
    "            )\n",
    "        ],\n",
    "        sliders=[{\n",
    "            \"active\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 20},\n",
    "                \"prefix\": \"Frame:\",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"right\"\n",
    "            },\n",
    "            \"transition\": {\"duration\": 50, \"easing\": \"cubic-in-out\"},\n",
    "            \"pad\": {\"b\": 10, \"t\": 50},\n",
    "            \"len\": 0.9,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0,\n",
    "            \"steps\": [\n",
    "                {\n",
    "                    \"args\": [[f.name], {\"frame\": {\"duration\": 50, \"redraw\": True}, \"mode\": \"immediate\"}],\n",
    "                    \"label\": str(k),\n",
    "                    \"method\": \"animate\",\n",
    "                }\n",
    "                for k, f in enumerate(fig.frames)\n",
    "            ],\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    fig.write_html('neural_mpc_results.html')\n",
    "    return entropy_mpc_pred\n",
    "# Call the function to plot the animation\n",
    "entropy_mpc_pred = plot_animated_trajectory_and_entropy_2d(all_trajectories, entropy_history, lambda_history, trees, lb, ub, durations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "vscode": {
   "interpreter": {
    "hash": "f0d7a494a3f776233427cb85a7e198c7cf4913b50a203c6febc678cc4f5bf265"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
