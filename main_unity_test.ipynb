{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train surrogate model\n",
    "\n",
    "With the previous data, train a surrogate model (gaussian process or NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "We use data from a file or a function generation to train a perception surrogate $g(\\Delta x)$.\n",
    "In this case $\\Delta x$ is defined as the relative position (distance) between a tree and the drone: $\\Delta x = \\| x - t_i \\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm  # For Gaussian PDF\n",
    "\n",
    "\n",
    "def load_data(polar=False, fixedView=False, ripe=True, n_input=3, subset_ratio=1.0, augment_data=True):\n",
    "    # Get the current working directory if __file__ is not available\n",
    "    script_dir = os.getcwd()  # Use current working directory as fallback\n",
    "\n",
    "    # Define the base directory for datasets\n",
    "    base_dir = os.path.join(script_dir, \"datasets\")  # Adjust subdirectory name as needed\n",
    "    \n",
    "    # Adjust paths based on parameters\n",
    "    base_dir = os.path.join(base_dir, \"polar\" if polar else \"cartesian\")\n",
    "    base_dir = os.path.join(base_dir, \"fixed_view\" if fixedView else \"variable_view\")\n",
    "    base_dir = os.path.join(base_dir, \"ripe\" if ripe else \"raw\")\n",
    "    \n",
    "    # Output CSV filename\n",
    "    output_csv_filename = 'SurrogateDatasetCNN.csv'\n",
    "\n",
    "    def find_latest_folder(base_dir):\n",
    "        \"\"\"Finds the latest dated folder in the base directory.\"\"\"\n",
    "        # List all subdirectories in the base_dir\n",
    "        subdirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "        \n",
    "        # Sort the directories by their modified time in reverse (latest first)\n",
    "        latest_folder = max(subdirs, key=lambda d: os.path.getmtime(os.path.join(base_dir, d)))\n",
    "        return os.path.join(base_dir, latest_folder)\n",
    "\n",
    "    # Find the latest dataset folder\n",
    "    latest_dataset_folder = find_latest_folder(base_dir=base_dir)\n",
    "    \n",
    "    # Create the full path to the CSV file\n",
    "    DATA_PATH = os.path.join(latest_dataset_folder, output_csv_filename)\n",
    "    print(f\"Loading data from: {DATA_PATH}\")\n",
    "    \n",
    "    # Initialize lists to store data\n",
    "    X = []  \n",
    "    Y = []\n",
    "    \n",
    "    # Read the CSV file\n",
    "    with open(DATA_PATH, 'r') as infile:\n",
    "        data = csv.reader(infile)\n",
    "        next(data)  # Skip the header\n",
    "        for row in data:\n",
    "            a, b, c, _, value_raw, value_ripe, _ = map(float, row)\n",
    "            \n",
    "            # Process input features\n",
    "            if n_input == 3:\n",
    "                # Normalize angle to [-π, π]\n",
    "                X.append([a, b, c])\n",
    "            else:\n",
    "                X.append([a, b])\n",
    "            \n",
    "            # Scale the target value\n",
    "            Y.append( ( value_ripe if ripe else (value_raw)) - 0.5)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    X_np = np.array(X)\n",
    "    Y_np = np.array(Y)\n",
    "    \n",
    "    # Randomly sample a subset of the data based on the subset_ratio\n",
    "    if subset_ratio < 1.0:\n",
    "        num_samples = int(len(X_np) * subset_ratio)\n",
    "        indices = np.random.choice(len(X_np), num_samples, replace=False)\n",
    "        X_np = X_np[indices]\n",
    "        Y_np = Y_np[indices]\n",
    "    \n",
    "    def generate_surrogate_augmented_data(X, num_samples):\n",
    "        x_min = (np.sqrt(X[:, 0]**2 + X[:, 1]**2)).min()\n",
    "        x_max = (np.sqrt(X[:, 0]**2 + X[:, 1]**2)).max()\n",
    "        yaw_values = [30, -30, 60, -60, 90, -90, 180, -180]\n",
    "        \n",
    "        synthetic_X = []\n",
    "        synthetic_Y = []\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            theta = random.uniform(-np.pi, np.pi)\n",
    "            r = random.choice([random.uniform(0, x_min), random.uniform(x_max, x_max +5)])\n",
    "            a = r * np.cos(theta) \n",
    "            b = r * np.sin(theta)\n",
    "            c = np.radians(random.choice(yaw_values))\n",
    "            value = 0.0\n",
    "            synthetic_X.append([a, b, c])\n",
    "            synthetic_Y.append(value)\n",
    "\n",
    "        return np.array(synthetic_X), np.array(synthetic_Y)\n",
    "\n",
    "    if not augment_data: return  torch.tensor(X_np, dtype=torch.float), torch.tensor(Y_np, dtype=torch.float)\n",
    "    # Generate augmented (synthetic) data\n",
    "    synthetic_X, synthetic_Y = generate_surrogate_augmented_data(X_np, int(len(X_np)*0.2))\n",
    "    \n",
    "    # Concatenate the original and synthetic datasets along the first axis (rows)\n",
    "    X_extended = np.concatenate((X_np, synthetic_X), axis=0)\n",
    "    Y_extended = np.concatenate((Y_np, synthetic_Y), axis=0)\n",
    "    \n",
    "    # Convert the extended arrays to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X_extended, dtype=torch.float)\n",
    "    Y_tensor = torch.tensor(Y_extended, dtype=torch.float)\n",
    "    return X_tensor, Y_tensor\n",
    "\n",
    "def fake_confidence(drone_pos, tree_pos, fov=40, dist_threshold = 5):\n",
    "    \"\"\"\n",
    "    Simulates the confidence output of the NN.\n",
    "    \"\"\"\n",
    "    direction = tree_pos - drone_pos[:2]\n",
    "    distance = np.sqrt(np.sum(direction**2))\n",
    "    result = np.full_like(distance, 0.5)\n",
    "    \n",
    "    \n",
    "    theta = drone_pos[2]\n",
    "    drone_forward = np.array([np.cos(theta), np.sin(theta)])\n",
    "    n_direction = direction / distance\n",
    "    ang_fov_tree = n_direction.T @ drone_forward  # Dot product (cos(angolo))\n",
    "    fov_threshold = np.cos(np.deg2rad(fov))\n",
    "    \n",
    "    if distance < 0.2 or distance > dist_threshold:\n",
    "        result = 0.5\n",
    "    elif ang_fov_tree >= fov_threshold and np.cos(np.arctan2(direction[1], direction[0])) > 0:  # Drone is facing the tree\n",
    "        result = norm.pdf(distance, loc=3.5, scale=2.0) + 0.5\n",
    "    return result\n",
    "\n",
    "def generate_fake_dataset(\n",
    "    samples_xy, \n",
    "    samples_yaw, \n",
    "    x_dimension, \n",
    "    use_fov=True,\n",
    "    x_low=-8,          # Lower bound for drone X position\n",
    "    x_high=8,          # Upper bound for drone X position\n",
    "    y_low=-8,          # Lower bound for drone Y position\n",
    "    y_high=8,          # Upper bound for drone Y position\n",
    "    tree_low=-8,       # Lower bound for tree position\n",
    "    tree_high=8        # Upper bound for tree position\n",
    "):\n",
    "    synthetic_X = []\n",
    "    synthetic_Y = []\n",
    "    \n",
    "    # Define ranges for drone positions with parameterized bounds\n",
    "    x_range = np.linspace(x_low, x_high, samples_xy)\n",
    "    y_range = np.linspace(y_low, y_high, samples_xy)\n",
    "    yaw_range = np.linspace(-np.pi, np.pi, samples_yaw)\n",
    "\n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            if use_fov:\n",
    "                for yaw in yaw_range:\n",
    "                    tree_pos = np.random.uniform(low=tree_low, high=tree_high, size=(1, 2))\n",
    "                    drone_pos = np.array([x, y, yaw])\n",
    "                    value = fake_confidence(drone_pos, tree_pos.flatten())\n",
    "                    synthetic_X.append(\n",
    "                        np.concatenate((drone_pos[:x_dimension], tree_pos.flatten()))\n",
    "                    )\n",
    "                    synthetic_Y.append(value)\n",
    "            else:\n",
    "                tree_pos = np.random.uniform(low=tree_low, high=tree_high, size=(1, 2))\n",
    "                drone_pos = np.array([x, y, np.arctan2(-y, -x)])\n",
    "                value = fake_confidence(drone_pos, tree_pos.flatten())\n",
    "                synthetic_X.append(\n",
    "                    np.concatenate((drone_pos[:x_dimension], tree_pos.flatten()))\n",
    "                )\n",
    "                synthetic_Y.append(value)\n",
    "    \n",
    "    return torch.Tensor(np.array(synthetic_X)), torch.Tensor(np.array(synthetic_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "hidden_layers = 8\n",
    "\n",
    "# Simple NN\n",
    "class MultiLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.input_layer = torch.nn.Linear(input_dim if not input_dim== 3 else input_dim+1, hidden_size)\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(3):\n",
    "            hidden_layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "\n",
    "        self.hidden_layer = torch.nn.ModuleList(hidden_layers)\n",
    "        self.out_layer = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if x.shape[-1] == 3:  # Check if the input has 3 dimensions\n",
    "            # Replace the angle with its sin and cos values\n",
    "            sin_cos =  torch.cat([torch.sin(x[..., -1:]), torch.cos(x[..., -1:])], dim=-1)\n",
    "            x = torch.cat([x[..., :-1], sin_cos], dim=-1)\n",
    "            x = self.input_layer(x)\n",
    "        for layer in self.hidden_layer:\n",
    "            x = torch.tanh(layer(x))\n",
    "        x = self.out_layer(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "train = True\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "epochs = 10\n",
    "validation_split = 0.3\n",
    "nn_input_dim = 3\n",
    "fixedView=False\n",
    "is_ripe = False\n",
    "\n",
    "X, Y =  load_data(fixedView=fixedView, ripe=is_ripe)\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Targets shape:\", Y.shape)\n",
    "\n",
    "if   train:\n",
    "    # Base directory to save models\n",
    "    base_model_dir = os.path.join(f\"saved_models_{nn_input_dim}d\",'unity_dataset')\n",
    "    os.makedirs(base_model_dir, exist_ok=True)\n",
    "    base_model_dir = os.path.join(base_model_dir,'ripe' if is_ripe else 'raw')\n",
    "    os.makedirs(base_model_dir, exist_ok=True)\n",
    "\n",
    "    # Create a new folder with the current timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_model_dir = os.path.join(base_model_dir, timestamp)\n",
    "    os.makedirs(run_model_dir, exist_ok=True)\n",
    "    print(\"Models will be saved in:\", run_model_dir)\n",
    "\n",
    "    # Prepare dataset\n",
    "    X = X[:,:3]\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    # Train-validation split\n",
    "    num_train_samples = int((1 - validation_split) * len(dataset))\n",
    "    num_val_samples = len(dataset) - num_train_samples\n",
    "    train_dataset, val_dataset = random_split(dataset, [num_train_samples, num_val_samples])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model =  MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    print(model)\n",
    "\n",
    "    # Set up TensorBoard logging\n",
    "    log_dir = f\"runs/fcn_{datetime.datetime.now().strftime('%Y)-%m-%d_%H-%M-%S')}\"\n",
    "    writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "    # Training loop with validation\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # Train step\n",
    "        train_loss = 0\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(x_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (x_batch, y_batch) in enumerate(val_loader):\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                y_pred = model(x_batch)\n",
    "                loss = criterion(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Log to TensorBoard\n",
    "        writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "        writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "        \n",
    "        # Save the model if validation loss improves\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            model_path = os.path.join(run_model_dir, f\"best_model_epoch_{epoch+1}.pth\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_latest_best_model(nn_input_dim, ripe):\n",
    "    # Base directory to save models\n",
    "    base_model_dir = os.path.join(f\"saved_models_{nn_input_dim}d\", 'unity_dataset')\n",
    "    base_model_dir = os.path.join(base_model_dir, 'ripe' if ripe else 'raw')\n",
    "    # Find the latest best model file\n",
    "    # List the run directories (assumed to be named with timestamps, e.g., \"20250204_153045\")\n",
    "    run_dirs = [d for d in os.listdir(base_model_dir) if os.path.isdir(os.path.join(base_model_dir, d))]\n",
    "    if not run_dirs:\n",
    "        raise ValueError(f\"No run directories found in: {base_model_dir}\")\n",
    "    \n",
    "    # Select the latest run directory (using lexicographical order assuming proper timestamp formatting)\n",
    "    latest_run = max(run_dirs)\n",
    "    latest_run_dir = os.path.join(base_model_dir, latest_run)\n",
    "    \n",
    "    # Within the latest run folder, find all files matching the best model naming pattern\n",
    "    best_model_files = [\n",
    "        f for f in os.listdir(latest_run_dir)\n",
    "        if re.match(r\"best_model_epoch_(\\d+)\\.pth\", f)\n",
    "    ]\n",
    "    if not best_model_files:\n",
    "        raise ValueError(f\"No best model files found in: {latest_run_dir}\")\n",
    "    \n",
    "    # Pick the file with the highest epoch number.\n",
    "    latest_model = max(\n",
    "        best_model_files,\n",
    "        key=lambda f: int(re.match(r\"best_model_epoch_(\\d+)\\.pth\", f).group(1))\n",
    "    )\n",
    "    \n",
    "    loaded_model = os.path.join(latest_run_dir, latest_model)\n",
    "    print(f'Loaded model: {loaded_model}')\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,  # 1 row, 2 columns\n",
    "    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],  # Both subplots are 3D scatter plots\n",
    "    subplot_titles=(\"Ground Truth\", \"Predicted\")  # Titles for each subplot\n",
    ")\n",
    "\n",
    "X_nn, _ = generate_fake_dataset(\n",
    "    samples_xy=80, \n",
    "    samples_yaw=1, \n",
    "    x_dimension=3,\n",
    "    use_fov=False,\n",
    "    x_low=-8,        # Drone X ranges from -10 to 10\n",
    "    x_high=8,\n",
    "    y_low=-8,         # Drone Y ranges from -5 to 5\n",
    "    y_high=8,\n",
    "    tree_low=0,     # Tree ranges from -15 to 15\n",
    "    tree_high=0\n",
    ")\n",
    "\n",
    "fig.add_trace(go.Scatter3d(z=Y.flatten(), x=X[:,0], y=X[:,1], name='Ground Truth',mode='markers',marker=dict(\n",
    "        color=Y.flatten(),  # Color based on z values\n",
    "        colorscale='Viridis',     # Use Viridis color map\n",
    "        colorbar=dict(title='Z Value'),  # Add color bar\n",
    "        size=5,                   # Marker size\n",
    "        opacity=0.8               # Marker opacity\n",
    "    ),), row=1, col=1)  # Add to the first subplot\n",
    "\n",
    "\n",
    "model = MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "model.load_state_dict(torch.load(get_latest_best_model(nn_input_dim, False)))\n",
    "model.eval()\n",
    "\n",
    "X = X[:,:3]\n",
    "# Model prediction\n",
    "with torch.no_grad():\n",
    "    y_test = model(X_nn[:,:3]).detach().numpy()\n",
    "\n",
    "# Add predicted trace to the second subplot\n",
    "fig.add_trace(go.Scatter3d(z=y_test.flatten(),x= X_nn[:,0],y= X_nn[:,1],name='Predicted',mode='markers',marker=dict(\n",
    "        color=y_test.flatten(),  # Color based on z values\n",
    "        colorscale='Viridis',     # Use Viridis color map\n",
    "        colorbar=dict(title='Z Value'),  # Add color bar\n",
    "        size=5,                   # Marker size\n",
    "        opacity=0.8               # Marker opacity\n",
    "    )\n",
    "), row=1, col=2)  # Add to the second subplot\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Ground Truth vs Predicted\",  # Main title\n",
    "    scene=dict(  # Update the first subplot's scene\n",
    "        xaxis_title=\"x1\",\n",
    "        yaxis_title=\"x2\",\n",
    "        zaxis_title=\"Output\"\n",
    "    ),\n",
    "    scene2=dict(  # Update the second subplot's scene\n",
    "        xaxis_title=\"x1\",\n",
    "        yaxis_title=\"x2\",\n",
    "        zaxis_title=\"Output\"\n",
    "    ),\n",
    "    showlegend=False  # Hide legend for clarity\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html('nn_surrogate_train_test.html')\n",
    "\n",
    "\n",
    "# Find the index of the maximum value in y_test\n",
    "max_index = np.argmax(y_test)\n",
    "x_best = X_nn[max_index, 0]\n",
    "y_best = X_nn[max_index, 1]\n",
    "\n",
    "# Vary the third input (yaw angle) between 0 and 2π\n",
    "yaw_values = np.linspace(-10, 10, 200)\n",
    "\n",
    "# Create a new input array with x_best and y_best fixed, and yaw_values varying\n",
    "X_new = np.column_stack([\n",
    "    np.full_like(yaw_values, x_best),\n",
    "    np.full_like(yaw_values, y_best),\n",
    "    yaw_values\n",
    "])\n",
    "\n",
    "# Convert to tensor for model inference\n",
    "X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "\n",
    "# Model prediction for the new input\n",
    "with torch.no_grad():\n",
    "    y_new = model(X_new_tensor).detach().numpy()\n",
    "\n",
    "# Create a new plot\n",
    "fig_new = go.Figure()\n",
    "\n",
    "# Add the trace for the new predictions\n",
    "fig_new.add_trace(go.Scatter(\n",
    "    x=np.rad2deg(yaw_values),\n",
    "    y=y_new.flatten(),\n",
    "    mode='lines',\n",
    "    name='Predicted Output',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig_new.update_layout(\n",
    "    title_text=f\"Output Inference with Fixed (x, y) = ({x_best:.2f}, {y_best:.2f}) and Varying Yaw\",\n",
    "    xaxis_title=\"Yaw Angle (radians)\",\n",
    "    yaxis_title=\"Output\",\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig_new.show()\n",
    "\n",
    "# Save the plot as HTML\n",
    "fig_new.write_html('nn_surrogate_varying_yaw.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the working environment\n",
    "\n",
    "The problem definition is as follows:\n",
    "\n",
    "$x$ state of the robot defined by the position of the drone and its velocity [x, y ,z, vx, vy, vz]\n",
    "\n",
    "$f(x, u)$ state transition function for the drone\n",
    "\n",
    "$u$ acceleration commands to the drone [ax, ay, az]\n",
    "\n",
    "$t \\in T$ tree positions for the $T$ trees [[tx_1, ty_2], ... , [tx_T, ty_T]]\n",
    "\n",
    "$\\lambda$ belief for the trees maturity confidence [\\lambda_1, ..., \\lambda_T] (values from 0 to 1). For practicity, it can be seen as part of $x$\n",
    "\n",
    "$z$ observation vector for the tree maturity confidence [z_1, ..., z_T] (values from 0 to 1)\n",
    "\n",
    "$g(\\Delta x)$ observation surrogate. It is applied to every tree.\n",
    "\n",
    "$b(\\lambda, z)$ bayesian update to the previous belief.\n",
    "\n",
    "$H(\\lambda)$ entropy function for the belief defined (for the case of binary distribution) as: $-\\lambda \\log{\\lambda} - (1-\\lambda) \\log(1-\\lambda)$.\n",
    "\n",
    "$J(\\lambda)$ the cost function of the MPC defined as: $\\sum_{1, ..., n} \\delta_1 H(\\lambda_i) * \\delta_2 \\Delta x_i^2 + \\delta_3 \\|u\\|$. They correspond to trying to reduce the entropy for each of the trees using $\\Delta x_i^2$ to guide the planner when there is no observation, and reduce the control inputs.\n",
    "\n",
    "The steps of the system are as follows:\n",
    "1. Load learned $g()$ which works for one tree.\n",
    "2. Initialize $x$ in a $x_0$ position, $\\lambda$ with $0.5$ values for each tree, and $t$ as known.\n",
    "3. Run the NMPC from $x$ for $N$ iterations. In each step:\n",
    "  - Compute $\\Delta x$ for each tree with the new drone $x$.\n",
    "  - Get estimation from NN for each tree: $z = g(\\Delta x)$.\n",
    "  - Fuse the estimation in $\\lambda$ for each tree: $\\lambda_{k} = b(\\lambda_{k-1}, z)$\n",
    "4. Apply the solution from the MPC.\n",
    "5. Get a real observation.\n",
    "6. Integrate the real observation into $\\lambda$.\n",
    "7. Go back to step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import casadi as ca\n",
    "# Define the entropy function\n",
    "def entropy(lambda_val):\n",
    "    return (-(lambda_val- 1e-6) * ca.log10(lambda_val -1e-6) - (1 - lambda_val  + 1e-6) * ca.log10(1 - lambda_val  + 1e-6))/ca.log10(2)\n",
    "\n",
    "# Generate lambda values (avoid 0 and 1 to prevent log(0) errors)\n",
    "x = np.linspace(0.0, 1.00, 100)\n",
    "output = []\n",
    "# Compute entropy values\n",
    "for i  in range(x.shape[0]):\n",
    "    output.append(entropy(x[i]))\n",
    "\n",
    "print(output[-1])\n",
    "# Plot the entropy function\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(x, output, label=\"Entropy\", color=\"blue\")\n",
    "plt.title(\"Entropy Function\")\n",
    "plt.xlabel(\"Lambda (λ)\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npc\n",
    "import casadi as ca\n",
    "import l4casadi as l4c\n",
    "import time\n",
    "import torch  # Assuming you use PyTorch for your neural network\n",
    "\n",
    "# =============================================================================\n",
    "# Global Constants\n",
    "# =============================================================================\n",
    "T = 1.0\n",
    "N = 4\n",
    "dt = T / N\n",
    "nx = 3  # (x, y, theta). The full state is 2*nx = 6: [x, y, theta, vx, vy, omega]\n",
    "\n",
    "# =============================================================================\n",
    "# Utility Functions\n",
    "# =============================================================================\n",
    "def generate_tree_positions(grid_size, spacing):\n",
    "    \"\"\"\n",
    "    Generate tree positions on a grid and add a small offset.\n",
    "    \"\"\"\n",
    "    x_positions = np.arange(0, grid_size[0] * spacing, spacing)\n",
    "    y_positions = np.arange(0, grid_size[1] * spacing, spacing)\n",
    "    xv, yv = np.meshgrid(x_positions, y_positions)\n",
    "    tree_positions = np.vstack([xv.ravel(), yv.ravel()]).T\n",
    "    return tree_positions + 0.1\n",
    "\n",
    "def get_domain(tree_positions):\n",
    "    \"\"\"\n",
    "    Returns the bounding box (lower and upper bounds) of the tree positions.\n",
    "    \"\"\"\n",
    "    x_min = np.min(tree_positions[:, 0])\n",
    "    x_max = np.max(tree_positions[:, 0])\n",
    "    y_min = np.min(tree_positions[:, 1])\n",
    "    y_max = np.max(tree_positions[:, 1])\n",
    "    return [x_min, y_min], [x_max, y_max]\n",
    "\n",
    "def kin_model():\n",
    "    \"\"\"\n",
    "    Kinematic model: state X = [x, y, theta, vx, vy, omega] and control U = [ax, ay, angular_acc].\n",
    "    Uses simple Euler integration.\n",
    "    \"\"\"\n",
    "    X = ca.MX.sym('X', nx * 2)  # 6 states\n",
    "    U = ca.MX.sym('U', nx)      # 3 controls\n",
    "    X_next = X + dt * ca.vertcat(X[nx:], U)\n",
    "    return ca.Function('F', [X, U], [X_next])\n",
    "\n",
    "def bayes(lambda_prev, z):\n",
    "    \"\"\"\n",
    "    Bayesian update for belief:\n",
    "       lambda_next = (lambda_prev * z) / (lambda_prev * z + (1 - lambda_prev) * (1 - z))\n",
    "    An epsilon term is added to avoid division by zero.\n",
    "    \"\"\"\n",
    "    prod = lambda_prev * z\n",
    "    return prod / (prod + (1 - lambda_prev) * (1 - z))\n",
    "\n",
    "def entropy(p):\n",
    "    \"\"\"\n",
    "    Compute the binary entropy of a probability p.\n",
    "    Values are clipped to avoid log(0).\n",
    "    \"\"\"\n",
    "    p = ca.fmin(p, 1 - 1e-6)\n",
    "    return (-p * ca.log10(p) - (1 - p) * ca.log10(1 - p))/ca.log10(2)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Modified MPC Optimization Function\n",
    "# =============================================================================\n",
    "def mpc_opt(g_nn, trees, lb, ub, x0, lambda_vals, entropy_horizon, steps=10):\n",
    "    \"\"\"\n",
    "    Set up and solve the MPC optimization problem with the following modifications:\n",
    "      - The robot moves according to the kinematic model.\n",
    "      - Only positions and translational velocities are constrained (orientation is free).\n",
    "      - A collision-avoidance (inequality) constraint ensures the robot stays a safe\n",
    "        distance from each tree.\n",
    "      - The objective now includes an entropy term that rewards the reduction in belief \n",
    "        uncertainty between the initial and final steps.\n",
    "      - **Modification:** If the predicted (expected) entropy reduction over the horizon is \n",
    "        lower than 1.0, then an extra attraction cost is added to pull the robot toward the \n",
    "        nearest tree with a belief (Bayes value) lower than 0.9.\n",
    "    \"\"\"\n",
    "    # Dimensions: state is 6-D; control is 3-D.\n",
    "    n_state = nx * 2   # 6\n",
    "    n_control = nx     # 3\n",
    "\n",
    "    opti = ca.Opti()\n",
    "    F_ = kin_model()  # Kinematic model function\n",
    "\n",
    "    # Decision variables:\n",
    "    X = opti.variable(n_state, steps + 1)\n",
    "    U = opti.variable(n_control, steps)\n",
    "\n",
    "    # Parameter vector: initial state and tree beliefs\n",
    "    P0 = opti.parameter(n_state + trees.shape[0]*2)\n",
    "    opti.subject_to(X[:, 0] == P0[: n_state])\n",
    "    # In this formulation, we use the current belief as a parameter (constant over the horizon)\n",
    "    lambda_param = P0[n_state:-trees.shape[0]]\n",
    "    lambda_horizon_param = P0[n_state + trees.shape[0]:]\n",
    "    # Convert tree positions to a CasADi DM for convenience.\n",
    "    trees_dm = ca.DM(trees)\n",
    "    num_trees = trees_dm.size1()\n",
    "\n",
    "    # ---------------------------\n",
    "    # Weights and Safety Parameters (tuned)\n",
    "    w_control    = 2.0      # Increased to smooth translational movements\n",
    "    w_ang        = 0.5      # Reduced to allow sharper turns when needed\n",
    "    w_entropy    = 1000.0    # Reduced to balance exploration vs. control effort\n",
    "    w_attr       = 0.0    # Increased to strengthen attraction to uncertain trees\n",
    "    safe_distance = 1.25      # Increased for safer obstacle avoidance\n",
    "    d_threshold   = 5.0      # Reduced to activate attraction earlier\n",
    "    penalty_scale = 1e4      # Reduced from 1e6 to avoid numerical stiffness\n",
    "\n",
    "    # Initialize the objective.\n",
    "    obj = 0\n",
    "    extra_costs = 0\n",
    "    # Create a list to hold the evolution of the belief.\n",
    "    # lambda_evol[0] is the initial belief.\n",
    "    lambda_evol = [lambda_param]\n",
    "\n",
    "    for i in range(steps):\n",
    "        # --- Constrain the State and Input ---\n",
    "        opti.subject_to(opti.bounded(lb[0] - 3.0, X[0, i + 1], ub[0] + 3.0))\n",
    "        opti.subject_to(opti.bounded(lb[1] - 3.0, X[1, i + 1], ub[1] + 3.0))\n",
    "        opti.subject_to(opti.bounded(-10.0, X[2, i + 1], 10.0))\n",
    "        opti.subject_to(opti.bounded(-10.0, X[3, i + 1], 10.0))\n",
    "        opti.subject_to(opti.bounded(-10.0, X[4, i + 1], 10.0))\n",
    "        opti.subject_to(opti.bounded(-20, U[0:2, i], 20))\n",
    "        opti.subject_to(opti.bounded(-3.14, U[-1, i], 3.14))\n",
    "        \n",
    "        # --- Dynamics Constraint ---\n",
    "        opti.subject_to(X[:, i + 1] == F_(X[:, i], U[:, i]))\n",
    "\n",
    "        # --- Obstacle Avoidance Constraint ---\n",
    "        # Ensure the robot remains at least safe_distance away from every tree.\n",
    "        delta = X[0:2, i+1] - trees_dm.T  # (2 x num_trees)\n",
    "        # Squared distances for each tree\n",
    "        sq_dists = ca.diag(ca.mtimes(delta.T, delta))\n",
    "        # The closest tree must be at least safe_distance away.\n",
    "        opti.subject_to(ca.mmin(sq_dists) >= safe_distance**2)\n",
    "        \n",
    "        # --- Neural Network Prediction & Bayesian Update ---\n",
    "        relative_pos_bayes = ca.repmat(X[0:2, i+1].T, num_trees, 1) - trees_dm\n",
    "        heading_bayes = ca.repmat(X[2, i+1], num_trees, 1)\n",
    "        nn_input = ca.horzcat(relative_pos_bayes, heading_bayes)\n",
    "        g_out = g_nn(nn_input)\n",
    "        z_k = (sq_dists > 100) * 0.5 + (sq_dists <= 100) *  ca.fmax(g_out, 0.5)  # Ensure a minimum confidence level\n",
    "        # Update the belief using the Bayesian update rule.\n",
    "        lambda_next = bayes(lambda_evol[-1], z_k)\n",
    "        lambda_evol.append(lambda_next)\n",
    "        # Reward entropy reduction along the horizon.\n",
    "        obj += w_entropy *( ca.sum1( (lambda_evol[0] < 0.95) * (entropy(lambda_next)))) #- entropy(lambda_evol[0])))) * ca.exp(-i/N)\n",
    "        \n",
    "        # --- Control Effort Regularization ---\n",
    "        obj += w_control * ca.sumsqr(U[0:2, i]) + w_ang * ca.sumsqr(U[2, i])\n",
    "\n",
    "        pos_i = X[0:2, i + 1]   # current (x, y)\n",
    "        theta_i = X[2, i + 1]   # current orientation\n",
    "        #theta_i_wrapped = ca.atan2(ca.sin(theta_i), ca.cos(theta_i))  # Wrap to [-π, π)\n",
    "        cost_list = []\n",
    "        \n",
    "        for j in range(num_trees):\n",
    "            tree_j = trees_dm[j, :].T\n",
    "            rel_ij = tree_j - pos_i          # vector from robot to tree j\n",
    "            d_ij = ca.norm_2(rel_ij)           # Euclidean distance\n",
    "            theta_des = ca.atan2(rel_ij[1], rel_ij[0])  # desired heading angle toward tree j\n",
    "            orient_error =( 1 - ca.cos(theta_i - theta_des)) **2 # misalignment cost\n",
    "            \n",
    "            # Penalty: high if the belief for this tree is high (i.e., tree is \"certain\").\n",
    "            penalty = penalty_scale * (0.5 + 0.5 * ca.tanh(100 * (lambda_horizon_param[j] - 0.95)))\n",
    "            \n",
    "            # Attraction multiplier: activates more when farther than d_threshold.\n",
    "            attraction_multiplier =  0.5 * (1 + ca.tanh(10 * (d_ij - d_threshold)))\n",
    "\n",
    "            cost_j =  attraction_multiplier + orient_error + penalty # d_ij + penalty\n",
    "\n",
    "            cost_list.append(cost_j)\n",
    "        cost_vec = ca.vertcat(*cost_list)\n",
    "        # Use the minimum cost among trees.\n",
    "        extra_costs += ca.mmin(cost_vec)\n",
    "        \n",
    "    # --- Extra Attraction if Entropy Reduction is Insufficient ---\n",
    "    # Compute the overall predicted entropy reduction over the horizon.\n",
    "    expected_reduction = ca.sum1(entropy(lambda_evol[0])) - ca.sum1(entropy(lambda_horizon_param))\n",
    "    # If the reduction is less than 1.0, the \"deficit\" is positive.\n",
    "    entropy_deficit =  ca.logsumexp(ca.vcat([(1.0- expected_reduction), 0.0 ]))\n",
    "    # For each tree, we use a smooth indicator that is near 1 if the belief is below 0.9,\n",
    "    # and near 0 if the belief is high. Then we add a large penalty for trees that are not sufficiently uncertain.\n",
    "\n",
    "    # Add extra attraction cost weighted by the entropy deficit.\n",
    "    obj +=  entropy_deficit * w_attr * extra_costs *( extra_costs < 1e4)\n",
    "\n",
    "    # Set the overall objective.\n",
    "    opti.minimize(obj)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Solver Options and Problem Solve\n",
    "    # ---------------------------\n",
    "    options = {\n",
    "        \"ipopt\": {\n",
    "            \"tol\": 1e-3,\n",
    "            \"warm_start_init_point\": \"yes\",\n",
    "            \"hessian_approximation\": \"limited-memory\",\n",
    "            \"print_level\": 0,\n",
    "            \"sb\": \"no\",\n",
    "            \"mu_strategy\": \"monotone\",\n",
    "            \"max_iter\": 3000\n",
    "        }\n",
    "    }\n",
    "    opti.solver(\"ipopt\", options)\n",
    "\n",
    "    # Set the parameter values.\n",
    "    opti.set_value(P0, ca.vertcat(x0, lambda_vals, entropy_horizon))\n",
    "    sol = opti.solve()\n",
    "\n",
    "    # Create the MPC step function for warm starting.\n",
    "    inputs = [P0, opti.x, opti.lam_g]\n",
    "    outputs = [U[:, 0], X, opti.x, opti.lam_g]\n",
    "    mpc_step = opti.to_function(\"mpc_step\", inputs, outputs)\n",
    "\n",
    "    return (mpc_step,\n",
    "            ca.DM(sol.value(U[:, 0])),\n",
    "            ca.DM(sol.value(X)),\n",
    "            ca.DM(sol.value(opti.x)),\n",
    "            ca.DM(sol.value(opti.lam_g)))\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main Loop\n",
    "# =============================================================================\n",
    "def main():\n",
    "    # --- Generate Environment ---\n",
    "    trees = generate_tree_positions([1, 1], 5.5)\n",
    "    lb, ub = get_domain(trees)\n",
    "    # Initial belief for each tree (e.g., 0.5 = uncertain)\n",
    "    lambda_k = ca.DM.ones(len(trees)) * 0.5\n",
    "    lambda_h = ca.DM.ones(len(trees))\n",
    "    mpc_horizon = N\n",
    "    print(ub,lb)\n",
    "    # --- Load Neural Network ---\n",
    "    # (Even though the NN is not used inside the MPC in this version,\n",
    "    #  we assume it is used in the overall system to update beliefs.)\n",
    "    nn_input_dim = 3  # relative position (2) + heading (1)\n",
    "    model = MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "    model.load_state_dict(torch.load(get_latest_best_model(nn_input_dim)))\n",
    "    model.eval()\n",
    "    g_nn = l4c.L4CasADi(model, batched=True, device='cuda')\n",
    "\n",
    "    # --- Initialize Robot State ---\n",
    "    # State: [x, y, theta, vx, vy, omega]\n",
    "    x_0 = ca.vertcat(ca.DM([-2.5, 22.5]) ,ca.DM.ones(1)*(-np.pi), ca.DM.zeros(nx))\n",
    "\n",
    "    # --- Logging Variables ---\n",
    "    all_trajectories = []\n",
    "    lambda_history = []\n",
    "    entropy_history = []\n",
    "    durations = []\n",
    "    z_history = []\n",
    "\n",
    "    # --- Initial MPC Setup ---\n",
    "    mpc_step, u, x_traj, x_dec, lam_dec = mpc_opt(g_nn, trees, lb, ub, x_0, lambda_k, lambda_h, mpc_horizon)\n",
    "    iteration = 0\n",
    "\n",
    "    while iteration < 300:\n",
    "        iteration += 1\n",
    "        for i in range(x_traj.full().shape[1]-1):\n",
    "            relative_position_robot_trees = np.tile(x_traj[:2, i+1].full().T, (trees.shape[0], 1)) - trees\n",
    "            distance_robot_trees = np.sqrt(np.sum(relative_position_robot_trees**2, axis=1))\n",
    "            theta = np.tile(x_traj.full()[2, i+1], (trees.shape[0], 1))  # Drone yaw\n",
    "            input_nn = ca.horzcat(relative_position_robot_trees, theta)\n",
    "            # Compute z_k using a neural network output (or similar)\n",
    "            z_k = ca.fmax(g_nn(input_nn), 0.5)\n",
    "            lambda_h = bayes(lambda_h, z_k)\n",
    "        \n",
    "        # Extract current state from the MPC trajectory (using the second state as current).\n",
    "        x_k = x_traj[:, 1].full().flatten()\n",
    "\n",
    "        # Simulate sensor observations for each tree.\n",
    "        z_k = ca.vertcat(*[fake_confidence(x_k, tree, fov=40) for tree in trees])\n",
    "        z_history.append(z_k.full().flatten())\n",
    "\n",
    "        # Update belief using the Bayesian update.\n",
    "        lambda_k = ca.fmin( bayes(lambda_k, z_k), 1 - 1e-6)\n",
    "\n",
    "        # Run MPC with updated state and belief. The previous solution (x_dec, lam_dec) is used as a warm start.\n",
    "        start_time = time.time()\n",
    "        u, x_traj, x_dec, lam_dec = mpc_step(ca.vertcat(x_k, lambda_k, lambda_h), x_dec, lam_dec)\n",
    "        durations.append(time.time() - start_time)\n",
    "\n",
    "        # Logging: compute total entropy and store history.\n",
    "        entropy_k = ca.sum1(entropy(lambda_k)).full().flatten()[0]\n",
    "        lambda_history.append(lambda_k.full().flatten().tolist())\n",
    "        entropy_history.append(entropy_k)\n",
    "        all_trajectories.append(x_traj.full().tolist())\n",
    "\n",
    "        lambda_h = lambda_k\n",
    "        \n",
    "        print(f\"Iteration {iteration}: x = {x_k}, Entropy sum = {entropy_k}, Beliefs = {lambda_k}\")\n",
    "\n",
    "        # Termination condition based on entropy.\n",
    "        if entropy_k < 2.75:\n",
    "            break\n",
    "\n",
    "    return all_trajectories, entropy_history, lambda_history, z_history, durations, g_nn, trees, lb, ub\n",
    "\n",
    "# =============================================================================\n",
    "# Entry Point\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "def plot_animated_trajectory_and_entropy_2d(all_trajectories, entropy_history, lambda_history, z_history, trees, lb, ub, computation_durations):\n",
    "    print(np.array(all_trajectories).shape)\n",
    "    \n",
    "    # Extract trajectory data\n",
    "    x_trajectory = np.array([traj[0] for traj in all_trajectories])\n",
    "    y_trajectory = np.array([traj[1] for traj in all_trajectories])\n",
    "    theta_trajectory = np.array([traj[2] for traj in all_trajectories])  # Drone orientation (yaw)\n",
    "    all_trajectories = np.array(all_trajectories)\n",
    "    lambda_history = np.array(lambda_history)\n",
    "    \n",
    "\n",
    "    # --- Some tunable parameters for the new attraction term ---\n",
    "    distance_threshold = 20.0   # [units] threshold distance for “nearby” trees\n",
    "    alpha = 20.0               # steepness for the smooth indicator\n",
    "    beta = 10.0                # steepness for the exponential activation (used below)\n",
    "\n",
    "    # Compute entropy reduction for each step\n",
    "    entropy_mpc_pred = []\n",
    "    attraction_history = []\n",
    "    for k in range(all_trajectories.shape[0]):\n",
    "        lambda_k = lambda_history[k]\n",
    "        entropy_mpc_pred_k = [entropy_history[k]]  # Start with the initial entropy value\n",
    "        for i in range(all_trajectories.shape[2]-1):\n",
    "            relative_position_robot_trees = np.tile(all_trajectories[k, :2, i+1], (trees.shape[0], 1)) - trees\n",
    "            distance_robot_trees = np.sqrt(np.sum(relative_position_robot_trees**2, axis=1))\n",
    "            theta = np.tile(all_trajectories[k, 2, i+1], (trees.shape[0], 1))  # Drone yaw\n",
    "            input_nn = ca.horzcat(relative_position_robot_trees, theta)\n",
    "            # Compute z_k using a neural network output (or similar)\n",
    "            z_k = ca.fmax(g_nn(input_nn), 0.5)\n",
    "            lambda_k = bayes(lambda_k, z_k)\n",
    "            reduction = ca.sum1(entropy(lambda_k)).full().flatten()[0]\n",
    "            entropy_mpc_pred_k.append(reduction)\n",
    "        entropy_mpc_pred.append(entropy_mpc_pred_k)\n",
    "\n",
    "\n",
    "        relative_pos = np.tile(all_trajectories[k, :2, 0].T, (trees.shape[0], 1))- trees\n",
    "        # Here, we impose that “each tree” is not too close.\n",
    "        # (If you intended a per‐tree constraint, you might need to loop over trees.)\n",
    "        # For now, we impose that the (squared) distance summed over all trees is >1.\n",
    "        d_vec =  np.diag(relative_pos @ relative_pos.T)  #ca.sumsqr(relative_pos)\n",
    "\n",
    "        # Compute the attraction term for step k\n",
    "        indicator_distance = 0.5 * (1 + np.tanh(alpha * (distance_threshold - d_vec)))\n",
    "        indicator_lambda = 0.5 * (1 + np.tanh(alpha * ( 0.8 - lambda_k)))\n",
    "        nearby_indicator = indicator_distance * indicator_lambda\n",
    "        nearby_count = np.sum(nearby_indicator)\n",
    "        attraction_activation = np.exp(-beta * nearby_count)\n",
    "\n",
    "        global_indicator_weighted = np.log((d_vec * (1-(lambda_k-0.5)*2) +1)) \n",
    "        global_count = np.sum(global_indicator_weighted)\n",
    "        att_cost = attraction_activation\n",
    "\n",
    "        # Store the attraction term value for step k\n",
    "        attraction_history.append(att_cost.flatten()[0])  # Convert to scalar and store\n",
    "\n",
    "\n",
    "    entropy_mpc_pred = np.array(entropy_mpc_pred)\n",
    "    attraction_history = np.array(attraction_history)\n",
    "\n",
    "    # Compute the sum of entropies for all trees at each frame\n",
    "    sum_entropy_history = entropy_history\n",
    "\n",
    "    # Compute cumulative computation durations\n",
    "    cumulative_durations = np.cumsum(computation_durations)\n",
    "    \n",
    "    # Create a subplot with 2 rows and 2 columns.\n",
    "    # Note: we use the lower-left cell (row=2, col=1) for the Z measurements bar chart.\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        column_widths=[0.7, 0.3],\n",
    "        row_heights=[0.6, 0.4],\n",
    "        specs=[\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"scatter\"}],   # Row 1: 2D map and Sum of Entropies plot\n",
    "            [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]          # Row 2: Z Measurements (Bar Chart) and Computation Durations plot\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # --------------------\n",
    "    # Subplot (1,1): Drone trajectory and trees on the 2D map\n",
    "    # --------------------\n",
    "    # Add the MPC Future Trajectory trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_trajectory[0],\n",
    "            y=y_trajectory[0],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"MPC Future Trajectory\",\n",
    "            line=dict(color=\"red\", width=4),\n",
    "            marker=dict(size=5, color=\"blue\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add the actual Drone Trajectory trace\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Drone Trajectory\",\n",
    "            line=dict(color=\"orange\", width=4),\n",
    "            marker=dict(size=5, color=\"orange\")\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add each tree as a scatter marker (initially red)\n",
    "    for i in range(trees.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[trees[i, 0]],\n",
    "                y=[trees[i, 1]],\n",
    "                mode=\"markers+text\",  # Add text to the markers\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=\"#FF0000\",  # initial red color\n",
    "                    colorscale=[[0, \"#FF0000\"], [1, \"#00FF00\"]],  # red to green\n",
    "                    cmin=0,\n",
    "                    cmax=1,\n",
    "                    showscale=False\n",
    "                ),\n",
    "                text=[f\"Tree {i}\"],  # Display only the tree ID\n",
    "                textposition=\"top center\",  # Position the text above the marker\n",
    "                name=f\"Tree {i}: λ={lambda_history[0][i]:.2f}\"  # Include Bayes value in the legend\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # --------------------\n",
    "    # Subplot (1,2): Sum of Entropies plot\n",
    "    # --------------------\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Sum of Entropies (Past)\",\n",
    "            line=dict(color=\"blue\", width=2),\n",
    "            marker=dict(size=5, color=\"blue\")\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Sum of Entropies (Future)\",\n",
    "            line=dict(color=\"purple\", width=2, dash=\"dot\"),\n",
    "            marker=dict(size=5, color=\"purple\")\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # --------------------\n",
    "    # Subplot (2,2): Computation Durations plot\n",
    "    # --------------------\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Computation Durations\",\n",
    "            line=dict(color=\"green\", width=2),\n",
    "            marker=dict(size=5, color=\"green\")\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # --------------------\n",
    "    # NEW: Subplot (2,1): Z Measurements Bar Chart\n",
    "    # --------------------\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(range(trees.shape[0])),  # x-axis: tree indices\n",
    "            y=z_history[0],                 # initial z measurements for each tree at step 0\n",
    "            marker_color=\"blue\",\n",
    "            name=\"Z Measurements\"\n",
    "        ),\n",
    "        \n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Add the bar plot for the attraction term\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=[trees.shape[0]],  # Place the attraction term at the end of the x-axis\n",
    "            y=[attraction_history[0]],  # Initial attraction term value\n",
    "            marker_color=\"red\",\n",
    "            name=\"Attraction Term\"\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "    # Fix the y-axis limits for the bar plot (row=2, col=1)\n",
    "    fig.update_yaxes(range=[0.5, 1.0], row=2, col=1)\n",
    "    # --------------------\n",
    "    # Create frames for animation\n",
    "    # --------------------\n",
    "    frames = []\n",
    "    for k in range(len(entropy_mpc_pred)):\n",
    "        # Update tree colors and labels based on lambda values\n",
    "        tree_data = []\n",
    "        for i in range(trees.shape[0]):\n",
    "            tree_data.append(\n",
    "                go.Scatter(\n",
    "                    x=[trees[i, 0]],\n",
    "                    y=[trees[i, 1]],\n",
    "                    mode=\"markers+text\",  # Add text to the markers\n",
    "                    marker=dict(\n",
    "                        size=10,\n",
    "                        color=[2*(lambda_history[k][i] - 0.5)],  # color value computed from lambda\n",
    "                        colorscale=[[0, \"#FF0000\"], [1, \"#00FF00\"]],\n",
    "                        cmin=0,\n",
    "                        cmax=1,\n",
    "                        showscale=False\n",
    "                    ),\n",
    "                    text=[f\"Tree {i}\"],  # Display only the tree ID\n",
    "                    textposition=\"top center\",  # Position the text above the marker\n",
    "                    name=f\"Tree {i}: λ={lambda_history[k][i]:.2f}\"  # Update legend with current Bayes value\n",
    "                )\n",
    "            )\n",
    "        # Update the sum of entropies plot data\n",
    "        sum_entropy_past = sum_entropy_history[:k+1]\n",
    "        sum_entropy_future = entropy_mpc_pred[k]\n",
    "        \n",
    "        # Update computation durations plot data\n",
    "        computation_durations_past = computation_durations[:k+1]\n",
    "        \n",
    "        # Create drone orientation arrows (for visualization on the 2D map)\n",
    "        x_start = x_trajectory[k]  # drone x positions along MPC horizon\n",
    "        y_start = y_trajectory[k]  # drone y positions\n",
    "        theta = theta_trajectory[k]  # drone yaw angles\n",
    "        x_end = x_start + 0.5 * np.cos(theta)\n",
    "        y_end = y_start + 0.5 * np.sin(theta)\n",
    "        list_of_actual_orientations = []\n",
    "        for x0, y0, x1, y1 in zip(x_start, y_start, x_end, y_end):\n",
    "            arrow = go.layout.Annotation(\n",
    "                dict(\n",
    "                    x=x1,\n",
    "                    y=y1,\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    text=\"\",\n",
    "                    showarrow=True,\n",
    "                    axref=\"x\", ayref=\"y\",\n",
    "                    ax=x0,\n",
    "                    ay=y0,\n",
    "                    arrowhead=3,\n",
    "                    arrowwidth=1.5,\n",
    "                    arrowcolor=\"red\"\n",
    "                )\n",
    "            )\n",
    "            list_of_actual_orientations.append(arrow)\n",
    "        \n",
    "        # Also add arrows for the actual drone trajectory (row 1, col 1)\n",
    "        x_start_actual = x_trajectory[:k+1, 0]\n",
    "        y_start_actual = y_trajectory[:k+1, 0]\n",
    "        theta_actual = theta_trajectory[:k+1, 0]\n",
    "        x_end_actual = x_start_actual + 0.5 * np.cos(theta_actual)\n",
    "        y_end_actual = y_start_actual + 0.5 * np.sin(theta_actual)\n",
    "        for x0, y0, x1, y1 in zip(x_start_actual, y_start_actual, x_end_actual, y_end_actual):\n",
    "            arrow = go.layout.Annotation(\n",
    "                dict(\n",
    "                    x=x1,\n",
    "                    y=y1,\n",
    "                    xref=\"x\", yref=\"y\",\n",
    "                    text=\"\",\n",
    "                    showarrow=True,\n",
    "                    axref=\"x\", ayref=\"y\",\n",
    "                    ax=x0,\n",
    "                    ay=y0,\n",
    "                    arrowhead=3,\n",
    "                    arrowwidth=1.5,\n",
    "                    arrowcolor=\"orange\"\n",
    "                )\n",
    "            )\n",
    "            list_of_actual_orientations.append(arrow)\n",
    "        \n",
    "         # Build the frame\n",
    "        frame = go.Frame(\n",
    "            data=[\n",
    "                # Trace 0: MPC Future Trajectory (row 1, col 1)\n",
    "                go.Scatter(\n",
    "                    x=x_trajectory[k],\n",
    "                    y=y_trajectory[k],\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"red\", width=4),\n",
    "                    marker=dict(size=5, color=\"blue\")\n",
    "                ),\n",
    "                # Trace 1: Drone Trajectory (row 1, col 1)\n",
    "                go.Scatter(\n",
    "                    x=x_trajectory[:k+1, 0],\n",
    "                    y=y_trajectory[:k+1, 0],\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"orange\", width=4),\n",
    "                    marker=dict(size=5, color=\"orange\")\n",
    "                ),\n",
    "                # Traces for trees (row 1, col 1)\n",
    "                *tree_data,\n",
    "                # Trace for Sum of Entropies (Past) (row 1, col 2)\n",
    "                go.Scatter(\n",
    "                    x=np.arange(len(sum_entropy_past)),\n",
    "                    y=sum_entropy_past,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"blue\", width=2),\n",
    "                    marker=dict(size=5, color=\"blue\")\n",
    "                ),\n",
    "                # Trace for Sum of Entropies (Future) (row 1, col 2)\n",
    "                go.Scatter(\n",
    "                    x=np.arange(k, k + len(sum_entropy_future)),\n",
    "                    y=sum_entropy_future,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"purple\", width=2, dash=\"dot\"),\n",
    "                    marker=dict(size=5, color=\"purple\")\n",
    "                ),\n",
    "                # Trace for Computation Durations (row 2, col 2)\n",
    "                go.Scatter(\n",
    "                    x=np.arange(len(computation_durations_past)),\n",
    "                    y=computation_durations_past,\n",
    "                    mode=\"lines+markers\",\n",
    "                    line=dict(color=\"green\", width=2),\n",
    "                    marker=dict(size=5, color=\"green\")\n",
    "                ),\n",
    "                # Trace for Z Measurements (Bar Chart) (row 2, col 1)\n",
    "                go.Bar(\n",
    "                    x=list(range(trees.shape[0])),\n",
    "                    y=z_history[k],\n",
    "                    marker_color=\"blue\",\n",
    "                    name=\"Z Measurements\"\n",
    "                ),\n",
    "                # Trace for Attraction Term (Bar Chart) (row 2, col 1)\n",
    "                go.Bar(\n",
    "                    x=[trees.shape[0]],  # Place the attraction term at the end of the x-axis\n",
    "                    y=[attraction_history[k]],  # Current attraction term value\n",
    "                    marker_color=\"red\",\n",
    "                    name=\"Attraction Term\"\n",
    "                )\n",
    "            ],\n",
    "            name=f\"Frame {k}\",\n",
    "            layout=dict(annotations=list_of_actual_orientations)\n",
    "        )\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Add frames to the figure\n",
    "    fig.frames = frames\n",
    "\n",
    "    # Update layout for the subplots and overall figure\n",
    "    fig.update_layout(\n",
    "        title=\"Drone Trajectory, Sum of Entropies, Computation Durations, and Z Measurements\",\n",
    "        # Subplot (1,1)\n",
    "        xaxis=dict(title=\"X Position\", range=[lb[0] - 3, ub[0] + 3]),\n",
    "        yaxis=dict(title=\"Y Position\", range=[lb[1] - 3, ub[1] + 3]),\n",
    "        # Subplot (1,2)\n",
    "        xaxis2=dict(title=\"Time Step\"),\n",
    "        yaxis2=dict(title=\"Sum of Entropies\"),\n",
    "        # Subplot (2,1): Z Measurements\n",
    "        xaxis3=dict(title=\"Tree Index\"),\n",
    "        yaxis3=dict(title=\"Z Measurement\"),\n",
    "        # Subplot (2,2): Computation Durations\n",
    "        xaxis4=dict(title=\"Time Step\"),\n",
    "        yaxis4=dict(title=\"Computation Duration (s)\"),\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        label=\"Play\",\n",
    "                        method=\"animate\",\n",
    "                        args=[None, {\"frame\": {\"duration\": 200, \"redraw\": True}, \"fromcurrent\": True}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Pause\",\n",
    "                        method=\"animate\",\n",
    "                        args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]\n",
    "                    )\n",
    "                ],\n",
    "                showactive=True,\n",
    "                x=0.1,\n",
    "                y=0\n",
    "            )\n",
    "        ],\n",
    "        sliders=[{\n",
    "            \"active\": 0,\n",
    "            \"yanchor\": \"top\",\n",
    "            \"xanchor\": \"left\",\n",
    "            \"currentvalue\": {\n",
    "                \"font\": {\"size\": 20},\n",
    "                \"prefix\": \"Frame:\",\n",
    "                \"visible\": True,\n",
    "                \"xanchor\": \"right\"\n",
    "            },\n",
    "            \"transition\": {\"duration\": 50, \"easing\": \"cubic-in-out\"},\n",
    "            \"pad\": {\"b\": 10, \"t\": 50},\n",
    "            \"len\": 0.9,\n",
    "            \"x\": 0.1,\n",
    "            \"y\": 0,\n",
    "            \"steps\": [\n",
    "                {\n",
    "                    \"args\": [[f.name], {\"frame\": {\"duration\": 50, \"redraw\": True}, \"mode\": \"immediate\"}],\n",
    "                    \"label\": str(k),\n",
    "                    \"method\": \"animate\",\n",
    "                }\n",
    "                for k, f in enumerate(fig.frames)\n",
    "            ],\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Show the figure and write it to an HTML file\n",
    "    fig.show()\n",
    "    fig.write_html('neural_mpc_results.html')\n",
    "    return entropy_mpc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_trajectories, entropy_history, lambda_history, z_history, durations, g_nn, trees, lb, ub = main()\n",
    "    # Call the function to plot the animation\n",
    "    entropy_mpc_pred = plot_animated_trajectory_and_entropy_2d(all_trajectories, entropy_history, lambda_history, z_history, trees, lb, ub, durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Data Generation and Model Inference\n",
    "# ---------------------------\n",
    "# (Assuming your helper functions and model class are already defined elsewhere)\n",
    "#\n",
    "# Generate a fake dataset for prediction.\n",
    "# (Note: you might also already have X and Y from elsewhere for the ground truth.)\n",
    "X_nn, Y = load_data(fixedView=False, augment_data=False)\n",
    "\n",
    "# Compute the expected yaw for each row using arctan2(-y, -x)\n",
    "expected_yaw = torch.atan2(-X_nn[:, 1], -X_nn[:, 0])\n",
    "    \n",
    "# Create a boolean mask where the actual yaw is close to the expected yaw within the given tolerance.\n",
    "mask = torch.isclose(np.rad2deg(np.deg2rad(X_nn[:, 2])), expected_yaw, atol=0.1)\n",
    "\n",
    "X_nn = X_nn[mask]\n",
    "Y = Y[mask]\n",
    "\n",
    "# Load your trained model and perform prediction on X_nn.\n",
    "model = MultiLayerPerceptron(input_dim=nn_input_dim)\n",
    "model.load_state_dict(torch.load(get_latest_best_model(nn_input_dim)))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Perform the model prediction\n",
    "with torch.no_grad():\n",
    "    y_test = model(torch.tensor(X_nn[:, :3], dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Compute Arrow Components for Orientation\n",
    "# ---------------------------\n",
    "# Define a scaling factor for the arrow length.\n",
    "arrow_scale = 0.04\n",
    "\n",
    "# For ground truth:\n",
    "gt_x = X_nn[:, 0]\n",
    "gt_y = X_nn[:, 1]\n",
    "gt_yaw = X_nn[:, 2]  # assumed to be the orientation (in radians)\n",
    "gt_output = Y.flatten()  # output values to use for coloring\n",
    "\n",
    "dx_gt = arrow_scale * np.cos(gt_yaw)\n",
    "dy_gt = arrow_scale * np.sin(gt_yaw)\n",
    "\n",
    "# For predicted:\n",
    "pred_x = X_nn[:, 0]\n",
    "pred_y = X_nn[:, 1]\n",
    "pred_yaw = X_nn[:, 2]\n",
    "pred_output = y_test.flatten()\n",
    "\n",
    "dx_pred = arrow_scale * np.cos(pred_yaw)\n",
    "dy_pred = arrow_scale * np.sin(pred_yaw)\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Create 2D Subplots with Scatter and Quiver\n",
    "# ---------------------------\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# --- Ground Truth Plot ---\n",
    "sc1 = ax1.scatter(gt_x, gt_y, c=gt_output, cmap='viridis', s=10, label='Drone Position')\n",
    "# For the quiver, we pass the same output array so that the arrows get colormapped.\n",
    "q1 = ax1.quiver(gt_x, gt_y, dx_gt, dy_gt, gt_output, cmap='viridis',\n",
    "                angles='xy', scale_units='xy', scale=0.1, width=0.02)\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_title('Ground Truth')\n",
    "ax1.grid(True)\n",
    "cb1 = fig.colorbar(sc1, ax=ax1)\n",
    "cb1.set_label('Output (Y)')\n",
    "\n",
    "# --- Predicted Plot ---\n",
    "sc2 = ax2.scatter(pred_x, pred_y, c=pred_output, cmap='viridis', s=10, label='Drone Position')\n",
    "q2 = ax2.quiver(pred_x, pred_y, dx_pred, dy_pred, pred_output, cmap='viridis',\n",
    "                angles='xy', scale_units='xy', scale=0.1, width=0.02)\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_title('Predicted')\n",
    "ax2.grid(True)\n",
    "cb2 = fig.colorbar(sc2, ax=ax2)\n",
    "cb2.set_label('Output (y_test)')\n",
    "\n",
    "plt.suptitle(\"Drone Conditions and Orientations: Ground Truth vs Predicted\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
